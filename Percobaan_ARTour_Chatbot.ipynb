{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osVlPzw0TCkd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalAveragePooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRYnnmrQdYCX"
      },
      "outputs": [],
      "source": [
        "with open('artour.json') as artour:\n",
        "  data = json.load(artour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brc6hW_ldYEA"
      },
      "outputs": [],
      "source": [
        "tags = []\n",
        "inputs = []\n",
        "outputs = {}\n",
        "for intent in data['intents']:\n",
        "  outputs[intent['tag']]=intent['output']\n",
        "  for lines in intent['input']:\n",
        "    inputs.append(lines)\n",
        "    tags.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ttGjvnVegTg"
      },
      "outputs": [],
      "source": [
        "my_data = pd.DataFrame({\"inputs\":inputs,\n",
        "                      \"tags\":tags})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eiiQAB0_ew2v",
        "outputId": "dfe42b6a-54da-4c62-87d3-c2ba7b2aa51e"
      },
      "outputs": [],
      "source": [
        "my_data.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "D-ylDNLbeykf",
        "outputId": "51d87f33-015a-42f6-c61c-20ce358bbea6"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "my_data['inputs'] = my_data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "my_data['inputs'] = my_data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "my_data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "factory = StopWordRemoverFactory()\n",
        "stopword = factory.create_stop_word_remover()\n",
        "\n",
        "my_data['inputs'] = my_data['inputs'].apply(lambda wrd:[stopword.remove(x) for x in wrd])\n",
        "my_data['inputs'] = my_data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "my_data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "my_data['inputs'] = my_data['inputs'].apply(lambda wrd:[stemmer.stem(x) for x in wrd])\n",
        "my_data['inputs'] = my_data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "my_data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# create stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# stemming process\n",
        "sentence = 'apa harimu menyenangkan'\n",
        "hasil = stemmer.stem(sentence)\n",
        "print(hasil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6lmmW7jfXWq"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(my_data['inputs'])\n",
        "train = tokenizer.texts_to_sequences(my_data['inputs'])\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(my_data['tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY1akh7fgP3l",
        "outputId": "38cab358-427f-4e23-fb92-1a101d034228"
      },
      "outputs": [],
      "source": [
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ7TwHIOgYR6",
        "outputId": "7eb2fbdc-4406-4d94-c949-19a46c3ebf80"
      },
      "outputs": [],
      "source": [
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"number of unique words : \", vocabulary)\n",
        "output_length = le.classes_.shape[0]\n",
        "print(\"output length: \", output_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW4UPJLngwXX"
      },
      "outputs": [],
      "source": [
        "i = Input(shape=(input_shape,))\n",
        "x = Embedding(vocabulary+1,10)(i)\n",
        "x = LSTM(10, return_sequences=True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(output_length, activation=\"softmax\")(x)\n",
        "model = Model(i,x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgEIDdJshPxC"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDi4g_XdhPy_",
        "outputId": "9f162f11-b91b-49f8-b513-a14ace085749"
      },
      "outputs": [],
      "source": [
        "train = model.fit(x_train, y_train, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "NVcT0-qShr01",
        "outputId": "13af6672-0ad5-4008-e89f-cdd4f1fb06b1"
      },
      "outputs": [],
      "source": [
        "plt.plot(train.history['accuracy'], label='training set accuracy')\n",
        "plt.plot(train.history['loss'], label='training set loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfX7flhdh8Rl"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "print(\"ARTour : Selamat Datang ARTourist!\")\n",
        "\n",
        "while True:\n",
        "  texts_p = []\n",
        "  prediction_input = input('You : ')\n",
        "  #if prediction_input == 'keluar':\n",
        "  #  print(\"ARTour : Terima kasih telah berkunjung :D, selamat menikmati liburan Anda~\")\n",
        "  #  break\n",
        "  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input], input_shape)\n",
        "\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "  print(\"ARTour : \", random.choice(outputs[response_tag]))\n",
        "  #if response_tag < 0.5:\n",
        "  #  print(\"ARTour : Maaf, bisa diulang pertanyaannya?\")\n",
        "  #  continue\n",
        "  if response_tag == 'keluar':\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Percobaan ARTour Chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
